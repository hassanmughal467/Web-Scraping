{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a000d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "#for email\n",
    "import smtplib\n",
    "from selenium import webdriver\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c40060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-10\n"
     ]
    }
   ],
   "source": [
    "today=datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af0e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term):\n",
    "    \"\"\"Generate a url from search term\"\"\"\n",
    "    template=\"https://www.amazon.com/s?k={}&ref=nb_sb_ss_ts-doa-p_2_8\"\n",
    "    search_term=search_term.replace(' ','+')\n",
    "    \n",
    "    #add the term query to url\n",
    "    url= template.format(search_term)\n",
    "    #add page queryplaceholder\n",
    "    url+='&page{}'\n",
    "    return url\n",
    "\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"extract and return data from single record\"\"\"\n",
    "    \n",
    "    #description and url\n",
    "    link=item.h2.a\n",
    "    description=item.h2.a.text.strip()\n",
    "    url=\"https://www.amazon.com\"+link.get(\"href\")\n",
    "    try:\n",
    "    # price\n",
    "        price_parent=item.find(\"span\",\"a-price\")\n",
    "        price_detail=price_parent.find(\"span\",\"a-offscreen\")\n",
    "        price=price_detail.text.strip()\n",
    "    except AttributeError:\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "    # review count\n",
    "        rate=item.find(\"span\",{\"class\":\"a-icon-alt\"})\n",
    "        rating=rate.text.strip()\n",
    "        review=item.find(\"span\",{\"class\":\"a-size-base s-underline-text\"})\n",
    "        review_count=review.text.strip()\n",
    "    except AttributeError:\n",
    "        rating=\"\"\n",
    "        review_count=\"\"\n",
    "    \n",
    "    result=(description,price,rating,review_count,url)\n",
    "    return result\n",
    "\n",
    "def main(search_term):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    #startup webdriver\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "    \n",
    "    records=[]\n",
    "    url=get_url(search_term)\n",
    "    \n",
    "    for page in range(1,3):\n",
    "        driver.get(url.format(page))\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        results = soup.find_all(\"div\",{\"data-component-type\":\"s-search-result\"})\n",
    "\n",
    "        for item in results:\n",
    "            record=extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "                \n",
    "    driver.close()\n",
    "    #save data to csv file\n",
    "    with open('DataAnalyst_tshirt_Dataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Description\",\"price\",\"rating\",\"review count\",\"url\"])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9483f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('data analyst tshirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411e9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    #startup webdriver\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "    \n",
    "    records=[]\n",
    "    url=\"https://www.amazon.com/s?k=data%2Banalyst%2Btshirt&crid=32N0CLUEBGGWK&sprefix=data%2Bana%2Caps%2C441&ref=nb_sb_ss_ts-doa-p_2_8\"\n",
    "    \n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    results = soup.find_all(\"div\",{\"data-component-type\":\"s-search-result\"})\n",
    "\n",
    "    for item in results:\n",
    "        record=extract_record(item)\n",
    "        if record:\n",
    "            records.append(record)\n",
    "                \n",
    "    driver.close()\n",
    "    #save data to csv file\n",
    "    with open('DataAnalyst_tshirt_Dataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Description\",\"price\",\"rating\",\"review count\",\"url\"])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a25cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa402bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
